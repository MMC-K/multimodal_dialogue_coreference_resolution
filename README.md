# 멀티 모달 대화 내 상호참조해결을 위한 모델 학습 및 평가
- 멀티 모달 대화 내 상호참조해결을 위한 모델을 학습하는 코드와 평가하는 코드를 포함함.

# 문제 설명
- 발화와 이미지로 이루어진 대화가 있을 때, 발화자가 사용한 지시어나 대명사가 가리키는 실제 대상을 찾는 것.
- Image captioning 모델을 사용하여 이미지에 대한 내용을 대화 사이에 텍스트로 포함하는 상황을 가정함.
- 구체적으로, 발화 텍스트와 이미지 설명 텍스트로 구성된 대화가 주어지고 마지막에 발화자가 지시한 실제 대상을 찾는 것이 4지선다 문제로 나옴.
- 언어 모델은 4가지 보기 중 정답 보기를 출력해야함.
```
A: "내가 요즘 집에서 일할 때 찍은 사진을 올릴게."
(사진 1: 책상 위에 노트북과 헤드폰이 놓여있는 사진)

B: "오, 집에서 일할 때 저런 세팅이 편하겠다! 나도 방금 찍은 사진 하나 올릴게."
(사진 2: 소파 위에 책과 커피잔이 놓여있는 사진)

A: "응, 노트북이 있어서 일하기 편해. 헤드폰도 집중할 때 정말 유용해."

B: "나도 책 읽을 때 커피 한 잔이면 더 집중이 잘 되는 것 같아."

A: "맞아, 커피 한 잔이면 에너지도 충전되고 더 오래 일할 수 있지."

B: "그렇지! 이 분위기에서 책을 읽으면 정말 힐링이야."

A: "나도 그런 여유를 즐기고 싶어. 특히 저거 보니까 딱 그런 느낌이 들더라."

선택지:
A) A가 올린 사진 속 노트북
B) A가 올린 사진 속 헤드폰
C) B가 올린 사진 속 책
D) B가 올린 사진 속 커피잔

정답: D) B가 올린 사진 속 커피잔

--------------------------------
문제 풀이 과정:

정답에 대한 이유: A는 마지막 발화에서 '저거'라고 말하며 B의 사진에 대한 언급을 하고 있습니다. B는 사진 속에서 책과 커피잔을 소개했지만, 이전 발화에서 커피 한 잔을 강조하며 집중에 도움이 된다고 말했습니다. 마지막으로 A가 '저거'라고 한 것은 B가 커피와 관련된 이야기를 했을 때 자연스럽게 연결되는 커피잔입니다.

정답이 아닌 것에 대한 이유:

A의 노트북: A가 올린 사진이지만, '저거'라는 표현은 자신의 물건을 지칭하는 데 적합하지 않으며, 앞서 커피에 대한 대화가 이어졌습니다.
A의 헤드폰: 이 역시 A의 물건이며 대명사 '저거'로 지칭하기에 부자연스럽습니다.
B의 책: B의 사진 속 물건이긴 하지만, 대화 흐름상 커피에 집중하는 대화가 이어졌으므로 '저거'는 책보다는 커피잔을 가리킬 가능성이 더 큽니다.
```

# 실험 설정
- 데이터셋 `data/ai_response.json`
    - 데이터셋은 총 1726개의 대화로 구성됨.
    - 그 중 학습 데이터는 1380개, 테스트 데이터는 346개로 구성됨.

- 모델
    - 1B: meta-llama/Llama-3.2-1B
    - 3B: meta-llama/Llama-3.2-3B
    - 8B
        - meta-llama/Llama-3.1-8B
        - meta-llama/Llama-3.1-8B-Instruct

- 환경 및 하이퍼파라미터
    - GPU: A100 80GB 8대
    - Per-device batch size: 2
    - Gradient accumulation steps: 4
    - Epoch: 30
    - Warming-up steps: 100
    - Weight decay: 0.01
    - Learning rate: 2e-5
    - fp16: True

# 필요 패키지 설치
```bash
pip install -r requirements.txt
```



# 모델 학습
```bash
# 1B
bash ./scripts/train_1b.sh

# 3B
bash ./scripts/train_3b.sh

# 8B
bash ./scripts/train_8b.sh

# 8B-Instruct
bash ./scripts/train_8b_instruct.sh
```
# 모델 평가
```bash
# 1B, 3B, 8B
bash ./scripts/eval.sh

# 8B-Instruct
bash ./scripts/eval_instruct.sh
```

`logs/eval_*.txt` 파일에 평가 결과가 저장 됨.

# 실험 결과
| 모델크기 | 정확도<br>(물체 레벨) | 정확도<br>(사진 레벨) | 정확도<br>(물체 레벨<br>exact match) |
| -------- | ---------------- | ---------------- | ----------------------------- |
| 1B       | 0.80             | 0.93             | 0.70                          |
| 3B       | 0.84             | 0.97             | 0.65                          |
| 8B       | 0.81             | 0.95             | 0.68                          |
| 8B-Instruct       | 0.74             | 0.93             | 0.74                          |

- 3B 모델에서 가장 높은 정확도 (물체 레벨)를 달성하였음.
- 모델 파라미터가 8B로 늘어나도 성능이 오르지 않고 오히려 0.81로 줄어듦. 데이터가 적어서 그런 것으로 해석.
- 물체 레벨에 비해 사진 레벨에서 0.1 정확도 이상 정확도가 높았음. 명시적으로 물체를 선택할 수 있는 경우가 아니라 대화의 뉘앙스로 물체를 선택해야하는 경우가 있는데, 사진이 맞았더라도 여기서 성능 하락이 컸을 것으로 예상.
- “정확도 (물체레벨 exact match)”는 보기 번호로만 정답을 계산한 게 아니라 보기를 정확하게 언급하였는 지로 정확도를 계산한 것임. 그래서 “정확도 (물체 레벨)”에 비해 정확도가 낮음. 같은 보기를 반복하여 생성하는 경우가 가장 많았고 보기 전체를 모두 언급하는 경우도 있었음.
- 8B-Instruct의 경우, 정답이지만 문장을 길게 말하는 경우가 있어 오히려 점수가 높지 않았음.
```
예시1: 마지막 A의 발화에서 '저거'는 B가 올린 사진에 포함된 완성된 요리에 대한 언급입니다. 따라서 정답은 D) B가 올린 사진 속 완성된 요리입니다.
예시2: 마지막 A의 발화에서 '저거'는 B가 올린 사진에 포함된 손뜨개 작품을 가리키는 것으로 보입니다. 따라서 정답은 D) B가 올린 사진 속 손뜨개 작품입니다.
```
# Acknowledgement
본 연구는 정부(과학기술정보통신부)의 재원으로 지원을 받아 수행된 연구입니다. (No. RS-2022-II220320, 상황인지 및 사용자 이해를 통한 인공지능 기반 1:1 복합대화 기술 개발)